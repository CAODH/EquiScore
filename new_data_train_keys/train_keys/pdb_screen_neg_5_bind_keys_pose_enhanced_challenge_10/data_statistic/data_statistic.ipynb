{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "random.seed(0)\n",
    "from collections import defaultdict,Counter\n",
    "\n",
    "'''\n",
    "only add pose < 2A  , which pdb id in training \n",
    "add challenge decoys to active samples\n",
    "'''\n",
    "\n",
    "def filter_targets(file_paths,targets):\n",
    "    filtered_keys = []\n",
    "    for name in file_paths:\n",
    "        if name.split('/')[-1].split('_')[0] in targets:\n",
    "            filtered_keys.append(name)\n",
    "    return filtered_keys\n",
    "def get_part_data(data_dir,names,fast_num = 5,active_names = None):\n",
    "    # data_name = []\n",
    "    pro_decoy_pro = defaultdict(list)\n",
    "    for i in names:\n",
    "        pro = i.split('_')[0]\n",
    "        if active_names is None:\n",
    "            pro_decoy_pro[pro].append(i)\n",
    "        else:\n",
    "            if pro in active_names:\n",
    "                pro_decoy_pro[pro].append(i)\n",
    "\n",
    "    pro_decoy_pro_5 = defaultdict(list)\n",
    "    for key in pro_decoy_pro.keys():\n",
    "        if len(pro_decoy_pro[key]) <= fast_num:\n",
    "            # print(key)\n",
    "\n",
    "            pro_decoy_pro_5[key] = pro_decoy_pro[key]\n",
    "        else:\n",
    "            pro_decoy_pro_5[key] =pro_decoy_pro[key][:fast_num]\n",
    "    pro_decoy_pro_5 = sum(pro_decoy_pro_5.values(),[])\n",
    "    print('mean of actives : decoys in cross_decoys',np.mean(list(dict(Counter([i.split('_')[2] for i in pro_decoy_pro_5])).values())))\n",
    "    return [data_dir + name for name in pro_decoy_pro_5]\n",
    "def get_part_data_screen_pose(data_dir,names,fast_num = 5,active_names = None):\n",
    "    # data_name = []\n",
    "    pro_decoy_pro = defaultdict(list)\n",
    "    for i in names:\n",
    "        pro = i.split('_active')[0]\n",
    "        if active_names is None:\n",
    "            pro_decoy_pro[pro].append(i)\n",
    "        else:\n",
    "            # flag = pro.split('_')[0] + '_' + pro.split('_')[1]\n",
    "            if pro in active_names:\n",
    "                pro_decoy_pro[pro].append(i)\n",
    "\n",
    "    pro_decoy_pro_5 = defaultdict(list)\n",
    "    # print(' pro_decoy_pro_5',len( pro_decoy_pro_5))\n",
    "    for key in pro_decoy_pro.keys():\n",
    "        if len(pro_decoy_pro[key]) <= fast_num:\n",
    "            # print(key)\n",
    "\n",
    "            pro_decoy_pro_5[key] = pro_decoy_pro[key]\n",
    "        else:\n",
    "            pro_decoy_pro_5[key] =pro_decoy_pro[key][:fast_num]\n",
    "    pro_decoy_pro_5 = sum(pro_decoy_pro_5.values(),[])\n",
    "    print('mean of actives : decoys in cross_decoys',np.mean(list(dict(Counter([i.split('_')[2] for i in pro_decoy_pro_5])).values())))\n",
    "    # print('all decoy ',len(pro_decoy_pro_5)/len(active_names))\n",
    "    return [data_dir + name for name in pro_decoy_pro_5]\n",
    "def get_part_data_screen(data_dir,names,fast_num = 5,active_names = None):\n",
    "    # data_name = []\n",
    "    pro_decoy_pro = defaultdict(list)\n",
    "    for i in names:\n",
    "        pro = i.split('-')[0]\n",
    "        if active_names is None:\n",
    "            pro_decoy_pro[pro].append(i)\n",
    "        else:\n",
    "            if pro in active_names:\n",
    "                pro_decoy_pro[pro].append(i)\n",
    "\n",
    "    pro_decoy_pro_5 = defaultdict(list)\n",
    "    # print(' pro_decoy_pro_5',len( pro_decoy_pro_5))\n",
    "    for key in pro_decoy_pro.keys():\n",
    "        if len(pro_decoy_pro[key]) <= fast_num:\n",
    "            # print(key)\n",
    "\n",
    "            pro_decoy_pro_5[key] = pro_decoy_pro[key]\n",
    "        else:\n",
    "            pro_decoy_pro_5[key] =pro_decoy_pro[key][:fast_num]\n",
    "    pro_decoy_pro_5 = sum(pro_decoy_pro_5.values(),[])\n",
    "    print('mean of actives : decoys in cross_decoys',np.mean(list(dict(Counter([i.split('_')[2].split('-')[1] for i in pro_decoy_pro_5])).values())))\n",
    "    # print('all decoy ',len(pro_decoy_pro_5)/len(active_names))\n",
    "    return [data_dir + name for name in pro_decoy_pro_5]\n",
    "#------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def select_uniport_for_val(eight_class_remove_duplicated,uniport_to_pdb_dict,rate = 0.12,seed = 42):\n",
    "    np.random.seed(seed)\n",
    "    val_uniport_ids = []\n",
    "    val_uniport_pdb_ids =[]\n",
    "    for uniport_set in eight_class_remove_duplicated:\n",
    "        uniport_set = list(uniport_set)\n",
    "        size = int(rate*len(uniport_set))\n",
    "        val_uniport_ids.extend(np.random.choice(uniport_set,size = size))\n",
    "    for uniport_id in val_uniport_ids:\n",
    "\n",
    "        val_uniport_pdb_ids.extend(uniport_to_pdb_dict[uniport_id])\n",
    "    return val_uniport_ids,val_uniport_pdb_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdb actives pros : 15409\n",
      "cross_decoys_pros : 15403\n",
      "mean of actives : decoys in cross_decoys 9.33947753130363\n",
      " pdbbind len of decoys:  146938\n",
      "mean of actives : decoys in cross_decoys 39356.0\n",
      "pose enhanced samples:  39356\n",
      "screen pose pros:  12869\n",
      "all valid keys in pdbbind  54765\n"
     ]
    }
   ],
   "source": [
    "# 先获取了pdbbind 的数据\n",
    "\n",
    "# valid_keys = glob.glob('/home/caoduanhua/score_function/data/pdb_screen/active_pocket/*')\n",
    "valid_keys =glob.glob('/home/caoduanhua/score_function/data/D-PDBbind_PDBscreen/PDB_bind_active_pocket/*')\n",
    "# valid_keys +=glob.glob('/home/caoduanhua/score_function/data/general_refineset/generalset_active_pocket_without_h/*')\n",
    "active_pros = set([v.split('/')[-1].split('_')[0] for v in valid_keys])\n",
    "\n",
    "print('pdb actives pros :',len(active_pros))\n",
    "cross_decoys= os.listdir('/home/caoduanhua/score_function/data/D-PDBbind_PDBscreen/PDB_bind_cross_decoy_pocket/')\n",
    "\n",
    "cross_decoys_pros = set([v.split('/')[-1].split('_')[0] for v in cross_decoys])\n",
    "print('cross_decoys_pros :',len(cross_decoys_pros))\n",
    "cross_decoys_dir = '/home/caoduanhua/score_function/data/D-PDBbind_PDBscreen/PDB_bind_cross_decoy_pocket/'\n",
    "\n",
    "pdbbind_cross_decoys = get_part_data(cross_decoys_dir,cross_decoys,fast_num=10,active_names = active_pros)\n",
    "\n",
    "print(' pdbbind len of decoys: ',len(pdbbind_cross_decoys))\n",
    "#----------------------------------------------------------------\n",
    "############# add pose enhanced samples ###############\n",
    "\n",
    "cross_decoys_dir_pose = '/home/caoduanhua/score_function/data/general_refineset/pdbbind-data_arguement_active_2a_3_pocket-4/'\n",
    "poses = os.listdir('/home/caoduanhua/score_function/data/general_refineset/pdbbind-data_arguement_active_2a_3_pocket-4/')\n",
    "valid_keys_poses = get_part_data(cross_decoys_dir_pose,poses,fast_num=100,active_names = active_pros)\n",
    "print('pose enhanced samples: ',len(valid_keys_poses))\n",
    "print('screen pose pros: ',len(set([i.split('/')[-1].split('_')[0] for i in valid_keys_poses])))\n",
    "valid_keys += valid_keys_poses\n",
    "print('all valid keys in pdbbind ',len(valid_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all challedge decoys :  73731\n",
      "last challedge decoys :  66450\n",
      " pdbbind len of shape decoys + active + crossdecoy  + pose enhanced :  66450\n"
     ]
    }
   ],
   "source": [
    "valid_keys_decoys = glob.glob('/home/caoduanhua/score_function/data/general_refineset/pdbbind-shape_decoy_align_pocket-5/*')\n",
    "print('all challedge decoys : ',len(valid_keys_decoys))\n",
    "valid_keys_decoys  = [i for i in valid_keys_decoys if i.split('/')[-1].split('_')[0] in active_pros]\n",
    "print('last challedge decoys : ',len(valid_keys_decoys))\n",
    "valid_keys_decoys = valid_keys_decoys\n",
    "print(' pdbbind len of shape decoys + active + crossdecoy  + pose enhanced : ',len(valid_keys_decoys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicated tragets:  6745\n",
      "len of the before remove duplicated target:  15401\n",
      "len of the after remove duplicated target:  11179\n",
      "remove done!\n"
     ]
    }
   ],
   "source": [
    "with open('/home/caoduanhua/score_function/data/uniport_analysis/duplicated_with_independent_pdb_ids_from_uniport_id/all_dulicatedpdb_ids.pkl','rb') as f:\n",
    "    duplicated_targets = pickle.load(f)\n",
    "    print('duplicated tragets: ',len(duplicated_targets))\n",
    "dude_gene =  set(OrderedDict.fromkeys([v.split('/')[-1].split('_')[0] for v in valid_keys]))\n",
    "print('len of the before remove duplicated target: ',len(dude_gene))\n",
    "dude_gene = dude_gene - duplicated_targets\n",
    "print('len of the after remove duplicated target: ',len(dude_gene))\n",
    "print('remove done!')\n",
    "#-----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of of corss-docking deduplicated:  47930\n"
     ]
    }
   ],
   "source": [
    "print('len of of corss-docking deduplicated: ',len([k for k in valid_keys_decoys  if k.split('/')[-1].split('_')[0] in dude_gene]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('prolif': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "96436f40073403b92d0f6092870a4b0301a0bb0cd6de222383e9be5ad32e5880"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
